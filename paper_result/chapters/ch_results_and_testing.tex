\section{Results And Testing} \label{sec:results_and_testing}

\subsection{Performance Evaluation} \label{subsec:performance_evaluation}

{\responsemod
    The system is designed to use supervised algorithms for model generation. We used K-Nearest Neighbors, Decision Tree, Multilayer Perceptron, Random Forest, and Support Vector Machine algorithms for the classification problem. Performance metrics used for evaluation were accuracy, F1, precision, recall, area under the ROC Curve, and total prediction time. The preference assigned to this metric was accuracy, which had the first preference. The F1 score had the second preference. The preferences for the product, recall, and ROC were set to auto. The training approach was selected with care. The system generated a weightage of 1.0, 0.8, 0.4, 0.4, 0.4, and 0.25.

    During the automated training and selection process models with the highest Vscore being selected as the most-suited models. The \Cref{tab:vscores_models} show the Vscore of the models. From this Vscores SVM classifier is selected as the best-suited model for datasets 2, 3, and 4. Whereas the RF classifier is selected as the most-suited model for dataset 1.
}

\Cref{fig:perfromance_results_dataset_1,fig:perfromance_results_dataset_2,fig:perfromance_results_dataset_3,fig:perfromance_results_dataset_4} show that models trained with an automated system produced satisfactory results. A few models, like KNN, RF, and SVM, performed better than other models (DT) at the cost of higher prediction time. Whereas MLP models produced good overall results with lower prediction times.
\Crefrange{tab:performance_of_models_trained_on_dataset_1}{tab:performance_of_models_trained_on_dataset_4} show the overall performance of the models on their respective datasets in detail.

\subsection{Performance Error Calculation}
For error calculation, the best models are tested against the training datasets of other models. \Cref{fig:perfromance_delta_knn,fig:perfromance_delta_dt,fig:perfromance_delta_mlp,fig:perfromance_delta_rf,fig:perfromance_delta_svm} show the average error introduced when models are tested against the training datasets of other models. This chart shows that KNN, MLP, and SVM models introduced minimum errors, whereas DT and RF models introduced large amounts of error. \Cref{fig:perfromance_delta_svm} also shows that the SVM model produced similar errors across all datasets. This smaller difference in error suggests that the SVM classifier can be used for classification tasks of similar nature. {\responsemod \Crefrange{tab:performance_k_nearest_neighbors_multi}{tab:performance_support_vector_machine_multi} show the performance of the models when tested on other datasets in detail.}
