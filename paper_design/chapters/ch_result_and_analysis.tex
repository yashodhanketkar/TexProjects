\section{Result and Analysis}\label{sec:result_and_analysis}

\subsection{Dataset and Algorithm}\label{subsec:dataset_and_algorithm}

To test the selection system we are employing two models and one dataset. The dataset contains 201 records with 754 features [\citenum{parkinsons_disease_detection}]. The random forest algorithm and support vector machine algorithm is used to generate the models Model$_1$ and Model$_2$ respectively. The performance obtained from these two models is shown in the \autoref{tab:performance_analysis_of_dataset}.

\begin{table}[ht]
    \caption{Performance Analysis of Dataset}\label{tab:performance_analysis_of_dataset}
    \begin{tabular*}{\tblwidth}{@{}LLLL@{}}
        \toprule
        Performance Parameter & Model$_1$ & Model$_2$ \\
        \midrule
        $P_1$ \quad Accuracy & 0.8039 & 0.7451 \\
        $P_2$ \quad F1 Score & 0.875 & 0.84337 \\
        $P_3$ \quad Pricision & 0.8537 & 0.79546 \\
        $P_4$ \quad Recall & 0.8974 & 0.89744 \\
        $P_5$ \quad Area under ROC & 0.6987 & 0.57372 \\
        $P_6$ \quad Prediction Time & 0.5563 & 0.09806 \\
        \bottomrule
    \end{tabular*}
\end{table}

\subsection{Test Cases and Results}\label{subsec:test_cases_and_results}

We will use 4 cases to test the system. The test cases are:
\begin{enumerate}[{Case} I:]
    \item We did not provide any preference in the selection parameters. Hence the default weight for all parameters.
    \item We gave preference to parameters in this order:
          \begin{enumerate}[1.]
              \item Accuracy
              \item Pricision
              \item Area under ROC
              \item F1 Score
              \item Recall
          \end{enumerate}
          Also, the sixth parameter (prediction time) is set to 0.25 i.e. careful approach.
    \item In this case, we used the same preferences from case II except for the sixth parameter, where we used the default value.
    \item Similar to the previous case we only changed the sixth parameter to 0.75 i.e. the faster approach.
\end{enumerate}
\autoref{tab:wieghtage_for_cases}, shows the weight values for each case.

We used \autoref{eq:V_score_formula} to calculate the $V_{score}$ of the models. The \autoref{tab:results_of_test_cases}, shows the $V_{score|Model_1}$, $V_{score|Model_2}$ values along with the model selected by the system.

\begin{table}[!hb]
    \caption{Weightage for cases}\label{tab:wieghtage_for_cases}
    \begin{tabular*}{\tblwidth}{@{}LLLLL@{}}
        \toprule
        Weights & Case$_1$ & Case$_2$ & Case$_3$ & Case$_4$ \\
        \midrule
        $w_1$ & 0.6 & 1.0 & 1.0 & 1.0 \\
        $w_2$ & 0.6 & 0.4 & 0.4 & 0.4 \\
        $w_3$ & 0.6 & 0.8 & 0.8 & 0.8 \\
        $w_4$ & 0.6 & 0.2 & 0.2 & 0.2 \\
        $w_5$ & 0.6 & 0.6 & 0.6 & 0.6 \\
        $w_6$ & 0.5 & 0.25 & 0.5 & 0.75 \\
        \bottomrule
    \end{tabular*}
\end{table}


\begin{table}[!hb]
    \caption{Results of test cases}\label{tab:results_of_test_cases}
    \begin{tabular*}{\tblwidth}{@{}LCCL@{}}
        \toprule
        Case & $V_{score|Model_1}$ & $V_{score|Model_2}$ & Model Selected \\
        \midrule
        I & 2.19907 & 2.26402 & Model$_2$ \\
        II & 2.29648 & 2.21802 & Model$_1$ \\
        III & 2.15741 & 2.19351 & Model$_2$ \\
        IV & 2.01834 & 2.16899 & Model$_2$ \\
        \bottomrule
    \end{tabular*}
\end{table}

\subsection{Key Findings}\label{subsec:key_findings}

From the data displayed in previous section, we saw how the system works on different datasets. These are a few key findings we obtained from that knowledge.
\begin{enumerate}
    \item The system successfully works with two different models.
    \item The scale of data does impact the efficiency and effectiveness of the system.
    \item The system successfully uses the weightage generated from the user requirements.
    \item The weightage of the user, especially the weight for time parameter significantly impacts the decision of the system.
\end{enumerate}

\subsection{Benefits of the System}\label{subsec:benefits_of_system}

The system can be used with any number of models. It allows users with limited prior knowledge easier access to machine learning technology. As seen in the previous section, the system can train models efficiently. The user-defined parameter weights lead to the selection of the best-suited model for particular tasks. The performance of models is stored for future evaluation of the system.

\subsection{Improvements On the System}\label{subsec:improvements_on_system}

Currently, the system is limited to only supervised machine learning algorithms. The supervised nature of these algorithms limits the training dataset to the labeled dataset. By providing support to unsupervised learning algorithms, systems can accommodate various types of training datasets. The selection parameters are adjusted before the training process. These predefined parameters restrict the selection choices of the system. Allowing users to tweak selection parameters after the training process will allow them to meet user requirements more efficiently.
