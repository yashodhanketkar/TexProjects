\section{Result and Analysis}\label{sec:result_and_analysis}


\subsection{Dataset and Test Cases}\label{subsec:dataset_and_test_cases}

To test the selection system we are employing two models and one dataset. The dataset contains 201 records with 754 features [\citenum{parkinsons_disease_detection}]. The random forest algorithm and support vector machine algorithm is used to generate the models Model$_1$ and Model$_2$ respectively. The performance obtained from these two models is shown in the \autoref{tab:performance_analysis_of_dataset}.

\begin{table}[ht]
    \caption{Performance Analysis of Dataset}\label{tab:performance_analysis_of_dataset}
    \begin{tabular*}{\tblwidth}{@{}LLLL@{}}
        \toprule
        Performance Parameter & Model$_1$ & Model$_2$ \\
        \midrule
        $P_1$ \quad Accuracy & 0.8039 & 0.7451 \\
        $P_2$ \quad F1 Score & 0.875 & 0.84337 \\
        $P_3$ \quad Pricision & 0.8537 & 0.79546 \\
        $P_4$ \quad Recall & 0.8974 & 0.89744 \\
        $P_5$ \quad Area under ROC & 0.6987 & 0.57372 \\
        $P_6$ \quad Prediction Time & 0.5563 & 0.09806 \\
        \bottomrule
    \end{tabular*}
\end{table}

We will use 4 cases to test the system. The test cases are:

\noindent
{\bfseries Case I:} We did not provide any preference in the selection parameters. Hence the default weight for all parameters.

\vspace*{0.5em}
\noindent
{\bfseries Case II:} We gave preference to parameters in this order:
        \begin{enumerate*}[label=\arabic{*}.]
            \item Accuracy
            \item Pricision
            \item Area under ROC
            \item F1 Score
            \item Recall.
        \end{enumerate*}

\noindent
Also, the sixth parameter (prediction time) is set to careful approach.

\vspace*{0.5em}
\noindent
{\bfseries Case III:} In this case, we used similar preferences from previous case except for the sixth parameter, where we selected default approach.

\vspace*{0.5em}
\noindent
{\bfseries Case IV:} Similar to the previous case we only changed the sixth parameter to the faster approach.

\vspace*{0.5em}
\autoref{tab:wieghtage_for_cases}, shows the weight values for each case.

\begin{table}[ht]
    \caption{Weightage for cases}\label{tab:wieghtage_for_cases}
    \begin{tabular*}{\tblwidth}{@{}LLLLL@{}}
        \toprule
        Weights & Case$_1$ & Case$_2$ & Case$_3$ & Case$_4$ \\
        \midrule
        $w_1$ & 0.6 & 1.0 & 1.0 & 1.0 \\
        $w_2$ & 0.6 & 0.4 & 0.4 & 0.4 \\
        $w_3$ & 0.6 & 0.8 & 0.8 & 0.8 \\
        $w_4$ & 0.6 & 0.2 & 0.2 & 0.2 \\
        $w_5$ & 0.6 & 0.6 & 0.6 & 0.6 \\
        $w_6$ & 0.5 & 0.25 & 0.5 & 0.75 \\
        \bottomrule
    \end{tabular*}
\end{table}


\subsection{Test Results}\label{subsec:results_and_discussion}
We used \autoref{eq:V_score_formula} to calculate the $V_{score}$ of the models. The \autoref{tab:results_of_test_cases}, shows the $V_{score}$ of Model$_1$ and Model$_2$ values along with the model selected by the system.

As seen in \autoref{tab:results_of_test_cases}, Model$_2$ is selected as the best model in three out of four cases. While Model$_1$ is selected as the best model is Case II, where we gave preference to a careful approach. The time parameter played an important role in the selection of the models compared to the other five parameters. Hence, implementation of the time parameter proved beneficial in the final selection of the model.

\begin{table}[ht]
    \caption{Results of test cases}\label{tab:results_of_test_cases}
    \begin{tabular*}{\tblwidth}{@{}LCCL@{}}
        \toprule
        Case & $V_{score}|$Model$_1$ & $V_{score}|$Model$_2$ & Model Selected \\
        \midrule
        I & 2.19907 & 2.26402 & Model$_2$ \\
        II & 2.29648 & 2.21802 & Model$_1$ \\
        III & 2.15741 & 2.19351 & Model$_2$ \\
        IV & 2.01834 & 2.16899 & Model$_2$ \\
        \bottomrule
    \end{tabular*}
\end{table}

\subsection{Key Findings}\label{subsec:key_findings}

From the data displayed in previous section, we saw how the system works on different datasets. These are a few key findings we obtained from that knowledge.
\setlist{nosep}
\begin{enumerate}
    \item The system successfully works with two different models.
    \item The scale of data does impact the efficiency and effectiveness of the system.
    \item The system successfully uses the weightage generated from the user requirements.
    \item The weightage of the user, especially the weight for time parameter significantly impacts the decision of the system.
\end{enumerate}

\subsection{Benefits of the System}\label{subsec:benefits_of_system}

The system can be used with any number of models. It allows users with limited prior knowledge easier access to machine learning technology. As seen in the previous section, the system can train models efficiently. The user-defined parameter weights lead to the selection of the best-suited model for particular tasks. The performance of models is stored for future evaluation of the system.

\subsection{Improvements On the System}\label{subsec:improvements_on_system}

Currently, the system is limited to only supervised machine learning algorithms. The supervised nature of these algorithms limits the training dataset to the labeled dataset. By providing support to unsupervised learning algorithms, systems can accommodate various types of training datasets. The selection parameters are adjusted before the training process. These predefined parameters restrict the selection choices of the system. Allowing users to tweak selection parameters after the training process will allow them to meet user requirements more efficiently.
